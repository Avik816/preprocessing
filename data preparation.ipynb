{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Code Authored by Avik Chakraborty. {-}\n",
    "# This program focuses mainly on Data Preparation of Time-Series Data. {-}\n",
    "# The dataset is a flight ticket price. {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the necesary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "import matplotlib.pyplot as mplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = pandas.read_excel('Train Set.xlsx')\n",
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = pandas.read_excel('Test Set.xlsx')\n",
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description.\n",
    "##### Airline : name of the airline.\n",
    "##### Date_of_Journey : start date of journey.\n",
    "##### Source : name of the city from where the airplane is departing.\n",
    "##### Destination : name of the city from where the airplane will arrive.\n",
    "##### Route : defines the route of the airplane.\n",
    "##### Dep_Time : departure time.\n",
    "##### Arrival_Time : arrival time.\n",
    "##### Duration : Duration of the flight.\n",
    "##### Total_Stops : number of places the airplane will stop between Source and Destination.\n",
    "##### Additional_Info : describes some additional info for the airplane.\n",
    "##### Price : price of the airplane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing.\n",
    "## Data Cleaning.\n",
    "### Checking for NAN values.\n",
    "#### Training Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset[(trainDataset['Route'].isna() == True) | (trainDataset['Total_Stops'].isna() == True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since there is only 1 NAN value in train dataset, removing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = trainDataset.drop(index = 9039, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### There is no NaN values in test dataset.\n",
    "### Checking for outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.boxplot(data = trainDataset, x = 'Price')\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier positions: [5 8]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Example multivariate data\n",
    "data = np.array([[10, 2], [12, 3], [11, 2.5], [14, 4], [13, 3.5], [17, 5], [12, 2.8], [10, 2.2], [100, 20], [11, 2.3]])\n",
    "\n",
    "# Train the Isolation Forest model\n",
    "clf = IsolationForest(contamination=0.2)  # `contamination` specifies the proportion of outliers\n",
    "clf.fit(data)\n",
    "\n",
    "# Predict outliers (-1 indicates outliers)\n",
    "predictions = clf.predict(data)\n",
    "outlier_positions = np.where(predictions == -1)[0]\n",
    "print(\"Outlier positions:\", outlier_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 17.,   5.],\n",
       "       [100.,  20.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[outlier_positions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation.\n",
    "### Dealing with Airline column.\n",
    "##### The unique values in the airline column is mapped with each airline representing a value. FOr e.g.: IndiGo = 1, Air India = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset['Airline'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset['Airline'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainDataset['Airline'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testDataset['Airline'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique values in the test set is same as the one in train set, therefore considering the unique values in train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueAirlines = [airline for airline in trainDataset['Airline'].unique()]\n",
    "uniqueAirlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "temp = {}\n",
    "\n",
    "for airline in uniqueAirlines:\n",
    "    temp.update({airline : count})\n",
    "    count += 1\n",
    "\n",
    "uniqueAirlines = temp\n",
    "del temp\n",
    "uniqueAirlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For training Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset['Airline'] = trainDataset['Airline'].map(uniqueAirlines)\n",
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Testing Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset['Airline'] = testDataset['Airline'].map(uniqueAirlines)\n",
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Date_of_Journey column in training set.\n",
    "##### a) Formatting the date into a datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset['Date_of_Journey'] = trainDataset['Date_of_Journey'].astype(dtype = 'datetime64[us]')\n",
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Dividing the date in Date_of_Journey dataset into date, month and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset['Journey_start_Date'] = trainDataset['Date_of_Journey'].dt.day\n",
    "trainDataset['Journey_start_Month'] = trainDataset['Date_of_Journey'].dt.month\n",
    "trainDataset['Journey_start_Year'] = trainDataset['Date_of_Journey'].dt.year\n",
    "trainDataset = trainDataset.drop(columns = ['Date_of_Journey'], axis = 1)\n",
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Shifting the rows from the end to the respective position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = pandas.concat([trainDataset.iloc[:, :1], trainDataset.iloc[:, 10:], trainDataset.iloc[:, 1:10]], axis = 1)\n",
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Date_of_Journey in testing set.\n",
    "##### a) Formatting the date into a datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset['Date_of_Journey'] = testDataset['Date_of_Journey'].astype(dtype = 'datetime64[us]')\n",
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Dividing the date in Date_of_Journey dataset into date, month and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset['Journey_start_Date'] = testDataset['Date_of_Journey'].dt.day\n",
    "testDataset['Journey_start_Month'] = testDataset['Date_of_Journey'].dt.month\n",
    "testDataset['Journey_start_Year'] = testDataset['Date_of_Journey'].dt.year\n",
    "testDataset = testDataset.drop(columns = ['Date_of_Journey'], axis = 1)\n",
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Shifting the rows from the end to the respective position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = pandas.concat([testDataset.iloc[:, :1], testDataset.iloc[:, -3:], testDataset.iloc[:, 1:9]], axis = 1)\n",
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Source and Destination column.\n",
    "##### In these two columns, the values from both the columns are considered as of equal importance as they hold the samilar category of data that is city values.\n",
    "##### a) The unique values are selected from both the columns.\n",
    "##### b) Values are combined and repeated values are removed.\n",
    "##### c) Then each city is assigned a particular numerical value.\n",
    "##### For e.g. : New Delhi = 1, Bangalore = 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Unique values in train set Source : {trainDataset['Source'].unique()}')\n",
    "print(f'Unique values in test set Source : {testDataset['Source'].unique()}')\n",
    "print(f'Unique values in train set Destination : {trainDataset['Destination'].unique()}')\n",
    "print(f'Unique values in test set Destination : {testDataset['Destination'].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As, we can see there are same cities in Source and Destination for both the sets. So mapping values on one set of unique values is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = []\n",
    "\n",
    "for columns in trainDataset['Source'].unique():\n",
    "    cities.append(columns)\n",
    "for columns in trainDataset['Destination'].unique():\n",
    "    cities.append(columns)\n",
    "\n",
    "cities = list(set(cities))\n",
    "cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cityMap = {}\n",
    "count = 1\n",
    "\n",
    "for city in cities:\n",
    "    cityMap.update({city : count})\n",
    "    count += 1\n",
    "    \n",
    "cityMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training set.\n",
    "trainDataset['Source'] = trainDataset['Source'].map(cityMap)\n",
    "trainDataset['Destination'] = trainDataset['Destination'].map(cityMap)\n",
    "\n",
    "# For Testing Set.\n",
    "testDataset['Source'] = testDataset['Source'].map(cityMap)\n",
    "testDataset['Destination'] = testDataset['Destination'].map(cityMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set.\n",
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Set.\n",
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the Route column in Training Set.\n",
    "#### Method 1.\n",
    "##### a) The city codes are extracted from the Route column.\n",
    "##### b) The unique codes are then seperated to new columns and then 0 is filled in each cell.\n",
    "##### c) When a particular city code is in the Route column, then 1 is assigned to that city route column at that particular index.\n",
    "##### For E.G. : Route at index 0 is BLR → DEL therefore, Route_BLR = 1 and Route_DEL = 1 everything else = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "routesUniqueCodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in trainDataset.index:\n",
    "    route = list(trainDataset.loc[index, 'Route'].split())\n",
    "    route = [r for r in route if len(r) != 1]\n",
    "    routesUniqueCodes.extend(route)\n",
    "\n",
    "routesUniqueCodes = list(set(routesUniqueCodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(routesUniqueCodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2.\n",
    "##### a) The unique Route are extracted from the Route column.\n",
    "##### b) The unique Routes will be seperated to new columns and then 0 will be filled in each cell.\n",
    "##### c) When a particular Route is in the Route column, then 1 will be assigned to that route column at that particular index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainDataset['Route'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainDataset['Route'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the Method 1, as it has less columns to work with, thus reducing high dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(42):\n",
    "    # Initially filling up with zero.\n",
    "    trainDataset['Route_' + routesUniqueCodes[i]] = 0\n",
    "\n",
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_route_map(index, routeMap):\n",
    "    for city in routeMap:\n",
    "        trainDataset.loc[index, 'Route_' + city] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in trainDataset.index:\n",
    "    routeMap = trainDataset.loc[index, 'Route'].split()\n",
    "    routeMap = [rm for rm in routeMap if len(rm) != 1]\n",
    "\n",
    "    # Updating the route city with 1.\n",
    "    update_route_map(index, routeMap)\n",
    "\n",
    "print('Updating Done !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the Route column and adjusting the position of the Route Maps in the Train Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the columns.\n",
    "trainDataset = trainDataset.drop(columns = ['Route'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the Route Maps.\n",
    "trainDataset = pandas.concat([trainDataset.iloc[:, 0:6], trainDataset.iloc[:, 12:], trainDataset.iloc[:, 6:12]], axis = 1)\n",
    "trainDataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For the 1st route map, the value it holds is 'BLR', 'DEL'.\n",
    "Therefore that column will hold the value one in that particular index,\n",
    "and route map as in 'Route_BLR' and 'Route_DEL' will have value 1 at index 0.'''\n",
    "trainDataset.iloc[0, 22:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As, we can see the values are updated in the particular route map in the training set.\n",
    "### Dealing with the Route column in Testing Set in the same manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "routesUniqueCodes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in testDataset.index:\n",
    "    route = list(testDataset.loc[index, 'Route'].split())\n",
    "    route = [r for r in route if len(r) != 1]\n",
    "    routesUniqueCodes.extend(route)\n",
    "\n",
    "routesUniqueCodes = list(set(routesUniqueCodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(routesUniqueCodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(38):\n",
    "    # Initially filling up with zero.\n",
    "    testDataset['Route_' + routesUniqueCodes[i]] = 0\n",
    "\n",
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_route_map(index, routeMap):\n",
    "    for city in routeMap:\n",
    "        testDataset.loc[index, 'Route_' + city] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in testDataset.index:\n",
    "    routeMap = testDataset.loc[index, 'Route'].split()\n",
    "    routeMap = [rm for rm in routeMap if len(rm) != 1]\n",
    "\n",
    "    # Updating the route city with 1.\n",
    "    update_route_map(index, routeMap)\n",
    "\n",
    "print('Updating Done !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the Route column and adjusting the position of the Route Maps in the Test Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the columns.\n",
    "testDataset = testDataset.drop(columns = ['Route'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the Route Maps.\n",
    "testDataset = pandas.concat([testDataset.iloc[:, 0:6], testDataset.iloc[:, 11:], testDataset.iloc[:, 6:11]], axis = 1)\n",
    "testDataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset.iloc[0, 19:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The values are updated in the particular Route Map in the testing set.\n",
    "### Dealing with the Dep_Time Column.\n",
    "##### Dividing the arrival time into hours and minutes columns.\n",
    "#### Training Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in trainDataset.index:\n",
    "    trainDataset.loc[index, 'Dep_Time_Hour'] = trainDataset.loc[index, 'Dep_Time'].split(':')[0]\n",
    "    trainDataset.loc[index, 'Dep_Time_Minutes'] = trainDataset.loc[index, 'Dep_Time'].split(':')[1]\n",
    "\n",
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = trainDataset.drop(columns = ['Dep_Time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = pandas.concat([trainDataset.iloc[:, :48], trainDataset.iloc[:, -2:], trainDataset.iloc[:, 48:53]], axis = 1)\n",
    "trainDataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in testDataset.index:\n",
    "    testDataset.loc[index, 'Dep_Time_Hour'] = testDataset.loc[index, 'Dep_Time'].split(':')[0]\n",
    "    testDataset.loc[index, 'Dep_Time_Minutes'] = testDataset.loc[index, 'Dep_Time'].split(':')[1]\n",
    "\n",
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = testDataset.drop(columns = ['Dep_Time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = pandas.concat([testDataset.iloc[:, :44], testDataset.iloc[:, -2:], testDataset.iloc[:, 44:48]], axis = 1)\n",
    "testDataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the Arrival_Time in the same manner.\n",
    "#### Training Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset['Arrival_Time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainDataset['Arrival_Time'].unique())\n",
    "print(len(trainDataset['Arrival_Time'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since, the arrival time has dates along with time dividing both the values into seperate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in trainDataset.index:\n",
    "    trainDataset.loc[index, 'Arrival_Time_Hour'] = trainDataset.loc[index, 'Arrival_Time'].split(':')[0]\n",
    "    \n",
    "    if len(trainDataset.loc[index, 'Arrival_Time'].split(':')[1]) > 2:\n",
    "        trainDataset.loc[index, 'Arrival_Time_Minutes'] = trainDataset.loc[index, 'Arrival_Time'].split(':')[1][0:2:1]\n",
    "\n",
    "        trainDataset.loc[index, 'Journey_End'] = trainDataset.loc[index, 'Arrival_Time'].split(':')[1][2::]\n",
    "    else:\n",
    "        trainDataset.loc[index, 'Arrival_Time_Minutes'] = trainDataset.loc[index, 'Arrival_Time'].split(':')[1]\n",
    "\n",
    "        trainDataset.loc[index, 'Journey_End'] = '-'\n",
    "\n",
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in trainDataset.index:\n",
    "    if trainDataset.loc[index, 'Journey_End'] != '-':\n",
    "        trainDataset.loc[index, 'Journey_End_Date'] = trainDataset.loc[index, 'Journey_End'].split()[0]\n",
    "        trainDataset.loc[index, 'Journey_End_Month'] = trainDataset.loc[index, 'Journey_End'].split()[1]\n",
    "    else:\n",
    "        trainDataset.loc[index, 'Journey_End_Date'] = 0\n",
    "        trainDataset.loc[index, 'Journey_End_Month'] = '-'\n",
    "\n",
    "trainDataset['Journey_End_Month'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mapping the months to the respective month number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset['Journey_End_Month'] = trainDataset['Journey_End_Month'].map({'Mar' : 3, 'Jun' : 6, 'May' : 5, 'Apr' : 4, '-' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = trainDataset.drop(columns = ['Arrival_Time', 'Journey_End'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = pandas.concat([trainDataset.iloc[:, :50], trainDataset.iloc[:, -4:], trainDataset.iloc[:, 50:54]], axis = 1)\n",
    "trainDataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset['Arrival_Time'].unique()[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in testDataset.index:\n",
    "    testDataset.loc[index, 'Arrival_Time_Hour'] = testDataset.loc[index, 'Arrival_Time'].split(':')[0]\n",
    "\n",
    "    if len(testDataset.loc[index, 'Arrival_Time'].split(':')[1]) > 2:\n",
    "        testDataset.loc[index, 'Arrival_Time_Minutes'] = testDataset.loc[index, 'Arrival_Time'].split(':')[1][0:2:1]\n",
    "        testDataset.loc[index, 'Journey_End'] = testDataset.loc[index, 'Arrival_Time'].split(':')[1][2::]\n",
    "\n",
    "    else:\n",
    "        testDataset.loc[index, 'Arrival_Time_Minutes'] = testDataset.loc[index, 'Arrival_Time'].split(':')[1]\n",
    "        testDataset.loc[index, 'Journey_End'] = '-'\n",
    "\n",
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in testDataset.index:\n",
    "    if testDataset.loc[index, 'Journey_End'] != '-':\n",
    "        testDataset.loc[index, 'Journey_End_Date'] = testDataset.loc[index, 'Journey_End'].split()[0]\n",
    "        testDataset.loc[index, 'Journey_End_Month'] = testDataset.loc[index, 'Journey_End'].split()[1]\n",
    "    else:\n",
    "        testDataset.loc[index, 'Journey_End_Date'] = 0\n",
    "        testDataset.loc[index, 'Journey_End_Month'] = '-'\n",
    "\n",
    "testDataset['Journey_End_Month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset['Journey_End_Month'] = testDataset['Journey_End_Month'].map({'Jun' : 6, 'May' : 5, 'Mar' : 3, 'Apr' : 4, '-' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = testDataset.drop(columns = ['Arrival_Time', 'Journey_End'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = pandas.concat([testDataset.iloc[:, :46], testDataset.iloc[:, -4:], testDataset.iloc[:, 46:49]], axis = 1)\n",
    "testDataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Duration.\n",
    "##### In this column the hours and minutes are converted into minutes, for easier calculation.\n",
    "#### Training Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in trainDataset.index:\n",
    "    duration = trainDataset.loc[index, 'Duration'].split()\n",
    "\n",
    "    if len(duration) == 2:\n",
    "        trainDataset.loc[index, 'Duration'] = int(duration[0][0:len(duration[0]) - 1:1])*60 + int(duration[1][0:len(duration[1]) - 1: 1])\n",
    "        \n",
    "\n",
    "    if len(duration) < 2:\n",
    "        if duration[0][-1:-2:-1] == 'h' or duration[0][- 1:-2:-1] == 'H':\n",
    "            trainDataset.loc[index, 'Duration'] = int(duration[0][0:len(duration[0]) - 1:1])*60\n",
    "        \n",
    "\n",
    "        if duration[0][-1:-2:-1] == 'm' or duration[0][-1:-2:-1] == 'M':\n",
    "            trainDataset.loc[index, 'Duration'] = int(duration[0][0:len(duration[0]) - 1:1])\n",
    "\n",
    "del duration\n",
    "trainDataset['Duration'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in testDataset.index:\n",
    "    duration = testDataset.loc[index, 'Duration'].split()\n",
    "\n",
    "    if len(duration) == 2:\n",
    "        testDataset.loc[index, 'Duration'] = int(duration[0][0:len(duration[0]) - 1:1])*60 + int(duration[1][0:len(duration[1]) - 1: 1])\n",
    "        \n",
    "\n",
    "    if len(duration) < 2:\n",
    "        if duration[0][-1:-2:-1] == 'h' or duration[0][- 1:-2:-1] == 'H':\n",
    "            testDataset.loc[index, 'Duration'] = int(duration[0][0:len(duration[0]) - 1:1])*60\n",
    "        \n",
    "\n",
    "        if duration[0][-1:-2:-1] == 'm' or duration[0][-1:-2:-1] == 'M':\n",
    "            testDataset.loc[index, 'Duration'] = int(duration[0][0:len(duration[0]) - 1:1])\n",
    "\n",
    "del duration\n",
    "testDataset['Duration'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the Total_Stops Column.\n",
    "##### Mapping the Total_Stops Columns as the number of stops between Source and Destination. For e.g.: 4 stops will be considered as 4. \n",
    "#### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset['Total_Stops'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset['Total_Stops'] = trainDataset['Total_Stops'].map({'non-stop' : 0, '2 stops' : 2, '1 stop' : 1, '3 stops' : 3, '4 stops' : 4})\n",
    "trainDataset['Total_Stops'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset['Total_Stops'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset['Total_Stops'] = testDataset['Total_Stops'].map({'non-stop' : 0, '2 stops' : 2, '1 stop' : 1, '3 stops' : 3, '4 stops' : 4})\n",
    "testDataset['Total_Stops'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with the Additional_Info column.\n",
    "##### Mapping the values with integer values.\n",
    "#### Training Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset['Additional_Info'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changing the 'No info' and and 'No Info' as 'No-info'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in trainDataset.index:\n",
    "    if trainDataset.loc[index, 'Additional_Info'] == 'No info':\n",
    "        trainDataset.loc[index, 'Additional_Info'] = 'No-info'\n",
    "    if trainDataset.loc[index, 'Additional_Info'] == 'No Info':\n",
    "        trainDataset.loc[index, 'Additional_Info'] = 'No-info'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_info = {}\n",
    "count = 0\n",
    "\n",
    "for values in trainDataset['Additional_Info'].unique():\n",
    "    add_info.update({values : count})\n",
    "    count += 1\n",
    "\n",
    "add_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset['Additional_Info'] = trainDataset['Additional_Info'].map(add_info)\n",
    "trainDataset['Additional_Info'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset['Additional_Info'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset['Additional_Info'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_info = {}\n",
    "count = 0\n",
    "\n",
    "for values in testDataset['Additional_Info'].unique():\n",
    "    add_info.update({values : count})\n",
    "    count += 1\n",
    "\n",
    "testDataset['Additional_Info'] = testDataset['Additional_Info'].map(add_info)\n",
    "testDataset['Additional_Info'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the data types of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training Set.\n",
    "for column in trainDataset.columns:\n",
    "    if trainDataset[column].dtype.name == 'object':\n",
    "        trainDataset[column] = trainDataset[column].astype('int64')\n",
    "\n",
    "# For testing Set.\n",
    "for column in testDataset.columns:\n",
    "    if testDataset[column].dtype.name == 'object':\n",
    "        testDataset[column] = testDataset[column].astype('int64')\n",
    "\n",
    "trainDataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Dataset.{-}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting them to CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset.to_csv('Cleaned Training Set.csv')\n",
    "testDataset.to_csv('Cleaned Testing Set.csv')\n",
    "\n",
    "print('File Saved !')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
